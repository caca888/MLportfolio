[![Makefile CI](https://github.com/caca888/MLportfolio/actions/workflows/makefile.yml/badge.svg)](https://github.com/caca888/MLportfolio/actions/workflows/makefile.yml)

# Porfolio Demo 

## Setup with Devlopment environment

* create virutal environment ```virtualenv ~/.venv```
* run the virtual environment ```source ~/.venv/bin/activate```
* add the virtual environment to bash shell ```vim ~/.bashrc```
* create Makefile ```touch Makefile```
* create requirements.txt ```touch requirements.txt```
* create source directory ```mkdir src``` with ```__init__.py``` for package include
* create test directory ```mkdir test```


## CI Environment

![CI Environment](/img/CI.PNG)

## RAG
[RAG essentials](https://github.com/caca888/MLportfolio/blob/main/rag/rag.py)
### Overview
This code implements a basic RAG system for processing and querying PDF documents. The system encodes the document content into a vetor store, which can be queried to retrieve relevant information.
### Key Components
1. User send a query
2. Document processing and text extraction are chunked for further steps
3. Vector store creation using FAISS and embedding to retrieve relevant document chunks
4. Retriever provides the relevant document chunks for context based on the query for LLM answering
5. LLM generates response
![RAG System](/img/rag.jpeg)

## RAG Optimizations
|Name|Description|Benefits|Link|
|---|---|---|---|
|Query Transformations for Improved Retrieval in RAG Systems | Three query transformation techniques: Query Rewriting, Step-back Prompting, and Sub-query Decomposition. | RAG sytems often face challenges in retrieving the most relevant information, especially when dealing with complex or ambiguous queries. These query transformation techniques address this issue by reformulating queries to better match relevant documents or to retrieve more comprehensive information.| [Query Transformations Implementation](https://github.com/caca888/MLportfolio/blob/main/rag/05_query_transformation.ipynb) |
|Hypothetical Document Embedding (HyDE) in Document Retrieval | Hypothetical Document Embedding (HyDE) system  is an innovative approach that transforms query questions into hypothetical documents containing the answer, aiming to bridge the gap between query and document distributions in vector space. | Traditional retrieval method often stuggle with the semantic gap between short queries and longer, more detailed documents. | [HyDE Implementation](https://github.com/caca888/MLportfolio/blob/main/rag/06_hypothetical_Doc_Emb.ipynb) |
| Context Enrichment Window for Document Retrieval | Context enrichtment window technique enhances the standard retrieval process by adding surrounding context to each retrieved chunk, improving the coherence and completeness of the returned information | Traditional vector search often returns isolated chunks of text, which may lack necessary context for full understanding. This approach aims to provide a more comprehensive view of the retrieved information by including neighboring text chunks | [Context Enrichment Window](https://github.com/caca888/MLportfolio/blob/main/rag/07_context_enrichment.ipynb) |
| Semantic Chunking for Document Processing | Semantic chunking aims to create more meaningful and context-aware text segments | Traditional text splitting methods often break documents at arbitrary points, potentially disrupting the flow of information and context. Semantic chunking addresses this issue by attempting to split text at more natural breakpoints, preserving semantic coherence within each chunk | [Semantic Chunking for Document Processing](https://github.com/caca888/MLportfolio/blob/main/rag/08_semantic_chunking_document.ipynb) |
| Contextual Compression in Document Retrieval | Contextual compression  aims to improve the relevance and conciseness of retrieved information by compressing and extracting the most pertinent parts of documents in the context of a given query | Traditional document retrieval systems often return entire chunks or documents, which may contain irrelevant information. Contextual compression addresses this by interlligently extracting and compressing only the most relevant parts of retrieved documents, leading to more focused and efficient information retrieval | [Contextual Compression in Document Retrieval](https://github.com/caca888/MLportfolio/blob/main/rag/09_contextual_compression.ipynb) |
| Document Augmentation Through Question Generation for Enhanced Retrieval | By generating and incorporating various questions related to each text fragment, the system enhances the standard retrieval process, thus increasing the likelihood of finding relevant documents that can be utilized as context for generative question answering | By enriching text fragments with related questions, we aim to significantly enhance the accuracy of identifying the most relevant sections of a document that contain answers to user queries | [Document Augmentation Through Question Generation for Enhanced Retrieval](https://github.com/caca888/MLportfolio/blob/main/rag/10_Document_Augmentation.ipynb) |
| Hybrid Search | Fusion Retrieval system combines vector-based similarity search with keyword-based BM25 retrieval. The approach aims to leverage the strengths of both methods to improve the overall quality and relevance of document retrieval | Traditional retrieval methods often reply on either semantic understanding (vector-based) or keyword matching (BM25). Each appraoch has its strengths and weaknesses. Fusion retrieval aims to combine these methods to create a more robust and accurate retrieval system that can handle a wider range of queries effiectively | [Hybrid Search](https://github.com/caca888/MLportfolio/blob/main/rag/11_fusion_retrieval.ipynb) |
| Reranking | Reranking ims to improve the relevance and quality of retrieved documents. It involves reassessing and reordering initially retrieved documents to ensure that the most pertinent information is prioritized for subsequent processing or presentation | The primary motivation for reranking in RAG systems is to overcome limitations of initial retrieval methods, which often rely on simpler similarity metrics. Reranking allows for more sophisticated relevance assessment, taking into account nuanced relationships between queries and documents that might be msised by traditional retrieval techniques. This process aims to enhance the overall preformance of RAG systems by ensuring that the most relevant information is ues in the generation phase | [Reranking Methods in RAG systems](https://github.com/caca888/MLportfolio/blob/main/rag/12_reranking.ipynb) | 
| Hierarchical Indices in Document Retrieval | Hierarchical Indexing system utilizing two levels of encoding: document-level summaries and detailed chunks. This approach aims to improve the efficiency and relevance of information retrieval by fist identifying relevant documnent sections through summaries, then drilling down to specific details within those sections | Traditional flat indexing methods can struggle with large documents or corpus, potentially missing context or returning irrelevant information. Hierarchical indexing addresses this by creating a two-tier search system, allowing for more efficient and context-aware retrieval | [Hierarchical Indices](https://github.com/caca888/MLportfolio/blob/main/rag/13_hierarchical_indices.ipynb) | 
| RAG with Feedback Loop | This system aims to improve the quality and relevance of responses over time by incorporating user feedback and dynamically adjusting the retrieval process | Tranditional RAG systems can sometimes produce inconsistent or irrelevant responses due to limitations in the retrieval process or the underlying knowledge base. By implementing a feedback loop, we can Continuously improve the quality of retrieved documents, Enhance the relevance of generated responses, and Adapt the system to user preferences and needs over time | [RAG with Feedback Loop](https://github.com/caca888/MLportfolio/blob/main/rag/14_retrieval_with_feedback.ipynb) |
| Explainable Retrieval in Document Serach | This system provides explainations for why each retrieved document is relevant. It combines vector-based similarity serach with natural langugage explanations, enhancing the transparency and interpretability of the retrieval process | Traditional document retrieval systems often work as black boxes, providing results without explaining why they were chosen. This lack of transparency can be problematic in scenarios where understanding the reasoning behind the results is crucial. The Explainable Retriever addresses this by offerin ginsights into the relevance of each retrieved document | [Explainable Retrieval](https://github.com/caca888/MLportfolio/blob/main/rag/16_explainable_retrieval.ipynb) |

## Advanced RAG Use Cases
|Name|Description|Benefits|Link|
|---|---|---|---|
| Adaptive RAG System | By leveraging LLM at various stages, it aims to provide more accurate, relevant, and context-aware responses to user queries | Traditional RAG systems often use a one-size-fits-all appraoch to retrieval, which can be suboptimal for different types of queries. Our adaptive system is motivated by the understanding that different typers of questions require different retrieval strategies. For example, a factual query might benefit from precise, focused retrieval, while an analytical query might require a broader, more diverse set of information | [Adaptive RAG](https://github.com/caca888/MLportfolio/blob/main/rag/15_adaptive_retrieval.ipynb) | 
| GraphRAG | It processes input documents to create a rich knowledge graph, which is then used to enhance the retrieval and generation of answers to user quries | Traditional RAG systems often struggle with maintaining context over long documents and makeing connections between related pieces of information. GraphRAG addresses these limitations by: 1. Representing knowledge as an interconnected graph, allowing for better preservation of relationships between concepts 2. Enabliing more intelligent traversal of information during the query process 3. Providing a visual representation of how information is connected and accessed during the answering process | [GraphRAG](https://github.com/caca888/MLportfolio/blob/main/rag/17_graphrag.ipynb) |
| RAPTOR | It aims to efficiently handle large document collections by creating a multi-level tree of summaries, allowing for both broad and details information retrieval | Traditional retrieval systems often struggle with large document sets, either missing important details or getting overwhelmed by irrelevant information. RAPTOR addresses this by creating a hierarchical structure of the document collection, allowing it to navigate between high-level concepts and specific details as needed | [RAPTOR](https://github.com/caca888/MLportfolio/blob/main/rag/18_raptor.ipynb) |
| self-RAG |  It dynamically decides whether to use retrieved information and how to best utilize it in generating responses, aiming to produce more accurate, relevant, and useful output | Traditional question-answering systems often struggle with balancing the use of retrieved information and the generation of new content. Some systems might rely too heavily on retrieved data, leading to responses that lack flexibility, while others might generate responses without sufficient grounding in factual information. Self-RAG addresses these issues by implementing a multi-step process that carefully evaluates the necessity and relevance of retrieved information, and assesses the quality of generated responses | [Self-RAG](https://github.com/caca888/MLportfolio/blob/main/rag/19_self_rag.ipynb) |
| Corrective RAG | It extends the standard RAG approach by dynamically evaluating and correcting the retrieval process, combining the power of vector db, web search, and language models to provide accurate and context-awawre responses to user quries | While traditional RAG systems have improved information retrieval and response generation, they can still fall short when the retrieval information is irrelevant or outdated. The corrective RAG process addresses these limitations by: 1. Leveraging pre-existing knowledge bases 2. Evaluating the relevance of retrieved information 3. Dynamically searching the web when necessary 4. Refining and combining knowledge from multiple sources 5. Generating human-like responses based on the most appropriate knowledge | [Corrective RAG](https://github.com/caca888/MLportfolio/blob/main/rag/20_corrective_rag.ipynb) |