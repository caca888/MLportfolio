{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothetical Document Embedding (HyDE) in Document Retrieval\n",
    "## Overview\n",
    "This code implements a Hypothetical Document Embedding (HyDE) system for document retrieval. HyDE is an innovative approach that transforms query questions into hypothetical documents containing the answer, aiming to bridge the gap between query and document distributions in vector space.\n",
    "## Movtivation\n",
    "Traditional retrieval method often stuggle with the semantic gap between short queries and longer, more detailed documents. HyDE addresses this by expanding the query into a full hypothetical document, potentially improving retrieval relevance by making the query respresntation more similar to the document representation in the vector space.\n",
    "## Key Components\n",
    "1. PDF processing and text chunking\n",
    "2. Vector store creation using FAISS and OpenAI embeddings\n",
    "3. Language model for generating hypothetical documetns\n",
    "4. Custom HyDEretriever class implementing the HyDE technique\n",
    "## Method Details\n",
    "### Docuemnt Preprocessing and Vector Store Creation\n",
    "1. The PDF is processed and split into chunks\n",
    "2. A FAISS vector store is created using OpenAI Embeddings for efficient similarity serach\n",
    "### Hypothetical Document Generation\n",
    "1. A langugage model is used to generate a hypothetical document that answers the given query\n",
    "2. The generation is guided by a prompt template that ensures the hypothetical document is detailed and matches the chunk size used in the vector store.\n",
    "### Retrieval Process\n",
    "The `HyDERetriever` calss implements the following steps:\n",
    "1. Generate a hypothetical document from the query using the language model\n",
    "2. use the hypothetical document as the search query in the vector store\n",
    "Retrieve the most similar documents to this hypothetical document\n",
    "## Key Features\n",
    "1. Query Expansion: Transforms short queries into detailed hypothetical documents\n",
    "2. Flexible Configuration: Allows adjustment of chunk size, overlap, and number of retrieved documents\n",
    "3. Integration with OpenAI models for hypothetical document generation and embeddings for vector representation\n",
    "## Benefits of this Approach\n",
    "1. Improved Relevance: By expanding queries into full documents, HyDE can potentailly capture more nuanced and relevant matches\n",
    "2. Handling Complex Queries: Particularly useful for complex or multi-faced queries that might be difficult to match directly\n",
    "3. Adaptability: The hypothetical document generation can adapt to different types of queries and document domains\n",
    "4. Potential for Better Context Understanding: The expanded query might better capture the context and intent behind the original question\n",
    "## Conclusion\n",
    "HyDE represents an innovative approach to document retrieval, addressing the semantic gap between queries and documents. By leveraging advanced langugage models to expand queries into hypothetical documents. HyDE has the potential to significantly improve retrieval relevance, especially for coplex or nuanced queries. This technique could be particularly valuable in domains where understanding query intent and context is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai.chat_models.azure import AzureChatOpenAI\n",
    "load_dotenv()\n",
    "openai_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai_api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_ID\")\n",
    "openai_api_version = os.getenv(\"AZURE_API_VERSION\")\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=openai_deployment,\n",
    "    api_version=\"2024-10-01-preview\",\n",
    "    azure_endpoint=f\"{openai_endpoint}openai/deployments/{openai_deployment}/chat/completions?api-version=2024-10-01-preview\",\n",
    "    temperature=0,\n",
    "    logprobs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # embeddings = get_langchain_embedding_provider(EmbeddingProvider.AZURE)\n",
    "    from langchain_openai.embeddings.azure import AzureOpenAIEmbeddings\n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "        deployment=openai_embedding,\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        chunk_size=16\n",
    "    )\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings.azure import AzureOpenAIEmbeddings\n",
    "openai_embedding = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_ID\")\n",
    "class HyDERetriever:\n",
    "    def __init__(self, files_path, chunk_size=500, chunk_overlap=100):\n",
    "        self.llm = AzureChatOpenAI(\n",
    "            azure_deployment=openai_deployment,\n",
    "            api_version=\"2024-10-01-preview\",\n",
    "            azure_endpoint=f\"{openai_endpoint}openai/deployments/{openai_deployment}/chat/completions?api-version=2024-10-01-preview\",\n",
    "            temperature=0,\n",
    "            logprobs=True,\n",
    "        )\n",
    "\n",
    "        self.embeddings = AzureOpenAIEmbeddings(\n",
    "            deployment=openai_embedding,\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            chunk_size=16\n",
    "        )\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = encode_pdf(files_path, chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap)\n",
    "    \n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"chunk_size\"],\n",
    "            template=\"\"\"Given the question '{query}', generate a hypothetical document that directly answers this question. The document should be detailed and in-depth.\n",
    "            the document size has be exactly {chunk_size} characters.\"\"\",\n",
    "        )\n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "\n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "\n",
    "    def retrieve(self, query, k=3):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = HyDERetriever(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "results, hypothetical_doc = retriever.retrieve(test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothetical_doc:\n",
      "\n",
      "Climate change is primarily caused by human activities that increase the concentration of greenhouse gases in the\n",
      "atmosphere. The burning of fossil fuels such as coal, oil, and natural gas for energy and transportation releases\n",
      "significant amounts of carbon dioxide (CO2). Deforestation and land-use changes also contribute by reducing the number\n",
      "of trees that can absorb CO2. Additionally, industrial processes and agricultural practices emit other potent greenhouse\n",
      "gases like methane (CH4) and nitrous oxide (N2O), exacerbating the greenhouse effect and leading to global warming.\n",
      "\n",
      "Context 1:\n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhou se gases.  \n",
      "Chapter 2: Causes of Climate Change  \n",
      "Greenhouse Gases  \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential\n",
      "\n",
      "\n",
      "Context 2:\n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate.  \n",
      "Fossil Fuels  \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked\n",
      "\n",
      "\n",
      "Context 3:\n",
      "and infrastructure. Cities are particularly vulnerable due to the \"urban heat island\" effect. \n",
      "Heatwaves can lead to heat -related illnesses and exacerbate existing h ealth conditions.  \n",
      "Changing Seasons  \n",
      "Climate change is altering the timing and length of seasons, affecting ecosystems and human \n",
      "activities. For example, spring is arriving earlier, and winters are becoming shorter and \n",
      "milder in many regions. This shift disrupts plant and animal life cycles a nd agricultural \n",
      "practices.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print(text_wrap(hypothetical_doc)+\"\\n\")\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
